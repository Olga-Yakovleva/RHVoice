#!/usr/bin/python2
# -*- coding: utf-8; mode: Python; indent-tabs-mode: t; tab-width: 4; python-indent: 4 -*-

# Copyright (C) 2012, 2014, 2015  Olga Yakovleva <yakovleva.o.v@gmail.com>

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import os.path
import argparse
import re
import codecs
import collections
import json

tag_regex=re.compile("<[^<]+>")

class base(object):
	def __init__(self,conf):
		self.replacements=conf["replace"]

	def replace(self,text):
		res=text
		for k,v in self.replacements.iteritems():
			res=res.replace(k,v)
		return res

class word_extractor(base):
	def __init__(self,conf):
		base.__init__(self,conf)
		self.alphabet=set(conf["alphabet"])
		alphabet_string=u"".join(sorted(self.alphabet))
		self.word_regex=re.compile(ur"(?ui)\b[{a}]+\b".format(a=alphabet_string))
		self.words=collections.Counter()

	def __call__(self,arg,dirname,filenames):
		for filename in filenames:
			path=os.path.join(dirname,filename)
			if os.path.isfile(path):
				with codecs.open(path,"r","utf-8") as f:
					for word in (m.group(0).lower() for m in self.word_regex.finditer(tag_regex.sub(" ",f.read()))):
#						letters=set(c for c in word if c.isalpha())
#						if letters.issubset(self.alphabet):
						self.words[self.replace(word)]+=1

def words(conf):
	ext=word_extractor(conf)
	os.path.walk(conf["source"],ext,None)
	with codecs.open("words","w","utf-8") as f:
		for w,c in ext.words.most_common():
			f.write(u"{} {}\n".format(w,c))

class sentence_selector(base):
	def __init__(self,conf):
		base.__init__(self,conf)
		self.count=0
		self.sentences=dict()
		self.words=set()
		with codecs.open("words","r","utf-8") as f:
			for line in f:
				w,n=line.split()
				if int(n)<conf["min_word_frequency"]:
					break
				self.words.add(w)
			self.min_length=conf["min_length"]
			self.max_length=conf["max_length"]
			self.vowels=set(conf["vowels"])
			self.ignore_case=conf["ignore_case"]
			self.allow_initialisms=conf["allow_initialisms"]
			self.plain=conf["plain"]
			self.wp_delim_regex=re.compile(u"(?u)\s*(?:</?doc(?:\s+[^<>]+)?>\s*)+")

	def add_paragraph(self,paragraph):
		remaining_tokens=collections.deque(self.replace(paragraph).split())
		sentence_tokens=list()
		while remaining_tokens:
			sentence_tokens.append(remaining_tokens.popleft())
			if self.is_sentence_boundary(sentence_tokens,remaining_tokens):
				if self.is_nice_sentence(sentence_tokens):
					sentence=u" ".join(sentence_tokens)
					if sentence not in self.sentences:
						self.sentences[sentence]=self.count
						self.count+=1
				sentence_tokens=list()

	def is_sentence_boundary(self,sentence_tokens,remaining_tokens):
		if not sentence_tokens:
			return False
		if not remaining_tokens:
			return True
		if not self.ignore_case:
			if not remaining_tokens[0].istitle():
				return False
		last_token=sentence_tokens[-1]
		if (last_token[-1]==".") and (len(last_token)>1) and last_token[-2].isalpha() and ((len(last_token)==2) or (not last_token[-3].isalpha())):
			return False
		for c in reversed(last_token):
			if c in [".","?","!"]:
				return True
			elif c.isalpha() or c.isdigit():
				return False
		return False

	def is_nice_sentence(self,tokens):
		if len(tokens) < self.min_length:
			return False
		if len(tokens) > self.max_length:
			return False
		if not self.ignore_case:
			if not tokens[0].istitle():
				return False
			for token in tokens[1:]:
				if not token.islower():
					return False
		for token in tokens[:-1]:
			word=token[:-1].lower() if token[-1]=="," else token.lower()
			if self.allow_initialisms and (len(word)==1) and (word not in self.vowels):
				return False
			if word not in self.words:
				return False
			if (not self.allow_initialisms) and (len(word) > 1) and (not next((c for c in word if c in self.vowels),None)):
				return False
		if tokens[-1][-1] not in [".","?"]:
			return False
		last_word=tokens[-1][:-1].lower()
		if self.allow_initialisms and (len(last_word)==1) and (last_word not in self.vowels):
			return False
		if last_word not in self.words:
			return False
		if (not self.allow_initialisms) and (not next((c for c in last_word if c in self.vowels),None)):
			return False
		return True

	def process_wikipedia_text(self,text):
		for article_text in self.wp_delim_regex.split(text):
			if article_text:
				clean_article_text=tag_regex.sub(u" ",article_text).replace("()","")
				for paragraph in clean_article_text.split("\n"):
					self.add_paragraph(paragraph)

	def process_plain_text(self,text):
		for paragraph in text.split("\n"):
			self.add_paragraph(paragraph)

	def __call__(self,arg,dirname,filenames):
		for filename in sorted(filenames):
			path=os.path.join(dirname,filename)
			if os.path.isfile(path):
				with codecs.open(path,"r","utf-8") as f:
					contents=f.read()
					if self.plain:
						self.process_plain_text(contents)
					else:
						self.process_wikipedia_text(contents)

def sentences(conf):
	sel=sentence_selector(conf)
	os.path.walk(conf["source"],sel,None)
	with codecs.open("sentences","w","utf-8") as f:
		for sentence,id in sorted(sel.sentences.iteritems(),key=lambda p: p[1]):
			f.write(sentence)
			f.write("\n")

if __name__=="__main__":
	parser=argparse.ArgumentParser(description="Select nice sentences for recording")
	parser.add_argument("--config",required=True,help="the path to the configuration file")
	subparsers=parser.add_subparsers()
	words_parser=subparsers.add_parser("words")
	words_parser.set_defaults(func=words)
	sentences_parser=subparsers.add_parser("sentences")
	sentences_parser.set_defaults(func=sentences)
	args=parser.parse_args()
	with open(args.config,"r") as f:
		conf=json.load(f)
	args.func(conf)
